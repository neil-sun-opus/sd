You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]
HumanEval Tasks:   0%|          | 0/164 [00:00<?, ?it/s]/home/ubuntu/miniconda3/envs/sd/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
HumanEval Tasks:   1%|          | 1/164 [00:01<05:13,  1.92s/it]HumanEval Tasks:   1%|          | 2/164 [00:03<03:51,  1.43s/it]HumanEval Tasks:   2%|▏         | 3/164 [00:04<03:30,  1.31s/it]HumanEval Tasks:   2%|▏         | 4/164 [00:05<03:43,  1.39s/it]HumanEval Tasks:   3%|▎         | 5/164 [00:09<05:56,  2.24s/it]HumanEval Tasks:   4%|▎         | 6/164 [00:13<07:29,  2.84s/it]HumanEval Tasks:   4%|▍         | 7/164 [00:16<07:53,  3.02s/it]HumanEval Tasks:   5%|▍         | 8/164 [00:20<08:13,  3.16s/it]HumanEval Tasks:   5%|▌         | 9/164 [00:22<07:44,  2.99s/it]HumanEval Tasks:   6%|▌         | 10/164 [00:24<06:56,  2.70s/it]HumanEval Tasks:   7%|▋         | 11/164 [00:30<09:03,  3.55s/it]HumanEval Tasks:   7%|▋         | 12/164 [00:33<08:19,  3.29s/it]HumanEval Tasks:   8%|▊         | 13/164 [00:34<06:55,  2.75s/it]HumanEval Tasks:   9%|▊         | 14/164 [00:37<06:39,  2.66s/it]HumanEval Tasks:   9%|▉         | 15/164 [00:38<05:39,  2.28s/it]HumanEval Tasks:  10%|▉         | 16/164 [00:39<04:34,  1.85s/it]HumanEval Tasks:  10%|█         | 17/164 [00:41<04:41,  1.91s/it]HumanEval Tasks:  11%|█         | 18/164 [00:42<04:18,  1.77s/it]HumanEval Tasks:  12%|█▏        | 19/164 [00:43<03:48,  1.58s/it]HumanEval Tasks:  12%|█▏        | 20/164 [00:44<03:03,  1.28s/it]HumanEval Tasks:  13%|█▎        | 21/164 [00:46<03:20,  1.40s/it]