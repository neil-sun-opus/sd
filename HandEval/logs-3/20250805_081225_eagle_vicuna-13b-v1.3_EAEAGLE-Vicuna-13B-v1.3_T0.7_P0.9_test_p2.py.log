LlamaForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
Loading EAGLE model from ../model_ckpt/EAGLE-Vicuna-13B-v1.3 with dtype float16
Base model: ../model_ckpt/vicuna-13b-v1.3
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.56s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.55s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.30s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.37s/it]
/home/ubuntu/sd/EAGLE/eagle/model/ea_model.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ea_layer_state_dict = torch.load(load_model_path,
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message
/home/ubuntu/sd/EAGLE/eagle/model/cnets1.py:510: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  weights = torch.load(local_emb_path)
Dataset: data-is-better-together/10k_prompts_ranked:   0%|          | 0/200 [00:00<?, ?it/s]/home/ubuntu/miniconda3/envs/sd/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/ubuntu/miniconda3/envs/sd/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Dataset: data-is-better-together/10k_prompts_ranked:   0%|          | 1/200 [00:02<08:11,  2.47s/it]Dataset: data-is-better-together/10k_prompts_ranked:   1%|          | 2/200 [00:04<07:04,  2.14s/it]Dataset: data-is-better-together/10k_prompts_ranked:   2%|â–         | 3/200 [00:06<07:16,  2.22s/it]Dataset: data-is-better-together/10k_prompts_ranked:   2%|â–         | 4/200 [00:09<07:42,  2.36s/it]Dataset: data-is-better-together/10k_prompts_ranked:   2%|â–Ž         | 5/200 [00:09<05:18,  1.63s/it]Dataset: data-is-better-together/10k_prompts_ranked:   3%|â–Ž         | 6/200 [00:11<05:54,  1.83s/it]Dataset: data-is-better-together/10k_prompts_ranked:   4%|â–Ž         | 7/200 [00:13<06:05,  1.89s/it]Dataset: data-is-better-together/10k_prompts_ranked:   4%|â–         | 8/200 [00:14<05:15,  1.64s/it]Dataset: data-is-better-together/10k_prompts_ranked:   4%|â–         | 9/200 [00:16<05:15,  1.65s/it]Dataset: data-is-better-together/10k_prompts_ranked:   5%|â–Œ         | 10/200 [00:17<04:57,  1.56s/it]Dataset: data-is-better-together/10k_prompts_ranked:   6%|â–Œ         | 11/200 [00:20<05:26,  1.73s/it]Dataset: data-is-better-together/10k_prompts_ranked:   6%|â–Œ         | 12/200 [00:20<04:15,  1.36s/it]Dataset: data-is-better-together/10k_prompts_ranked:   6%|â–‹         | 13/200 [00:22<04:39,  1.49s/it]Dataset: data-is-better-together/10k_prompts_ranked:   7%|â–‹         | 14/200 [00:24<04:45,  1.53s/it]Dataset: data-is-better-together/10k_prompts_ranked:   8%|â–Š         | 15/200 [00:25<04:36,  1.50s/it]Dataset: data-is-better-together/10k_prompts_ranked:   8%|â–Š         | 16/200 [00:28<05:38,  1.84s/it]Dataset: data-is-better-together/10k_prompts_ranked:   8%|â–Š         | 17/200 [00:30<05:40,  1.86s/it]Dataset: data-is-better-together/10k_prompts_ranked:   9%|â–‰         | 18/200 [00:31<04:59,  1.65s/it]Dataset: data-is-better-together/10k_prompts_ranked:  10%|â–‰         | 19/200 [00:32<05:01,  1.66s/it]Dataset: data-is-better-together/10k_prompts_ranked:  10%|â–ˆ         | 20/200 [00:33<04:13,  1.41s/it]Dataset: data-is-better-together/10k_prompts_ranked:  10%|â–ˆ         | 21/200 [00:35<04:32,  1.52s/it]Dataset: data-is-better-together/10k_prompts_ranked:  11%|â–ˆ         | 22/200 [00:37<04:35,  1.55s/it]Dataset: data-is-better-together/10k_prompts_ranked:  12%|â–ˆâ–        | 23/200 [00:38<04:47,  1.62s/it]Dataset: data-is-better-together/10k_prompts_ranked:  12%|â–ˆâ–        | 24/200 [00:41<05:38,  1.92s/it]Dataset: data-is-better-together/10k_prompts_ranked:  12%|â–ˆâ–Ž        | 25/200 [00:43<05:38,  1.94s/it]Dataset: data-is-better-together/10k_prompts_ranked:  13%|â–ˆâ–Ž        | 26/200 [00:45<05:28,  1.89s/it]Dataset: data-is-better-together/10k_prompts_ranked:  14%|â–ˆâ–Ž        | 27/200 [00:46<05:15,  1.82s/it]Dataset: data-is-better-together/10k_prompts_ranked:  14%|â–ˆâ–        | 28/200 [00:48<04:52,  1.70s/it]Dataset: data-is-better-together/10k_prompts_ranked:  14%|â–ˆâ–        | 29/200 [00:50<05:21,  1.88s/it]Dataset: data-is-better-together/10k_prompts_ranked:  15%|â–ˆâ–Œ        | 30/200 [00:52<05:33,  1.96s/it]Dataset: data-is-better-together/10k_prompts_ranked:  16%|â–ˆâ–Œ        | 31/200 [00:54<05:34,  1.98s/it]Dataset: data-is-better-together/10k_prompts_ranked:  16%|â–ˆâ–Œ        | 32/200 [00:57<06:08,  2.19s/it]Dataset: data-is-better-together/10k_prompts_ranked:  16%|â–ˆâ–‹        | 33/200 [00:59<05:48,  2.08s/it]Dataset: data-is-better-together/10k_prompts_ranked:  17%|â–ˆâ–‹        | 34/200 [01:00<05:18,  1.92s/it]Dataset: data-is-better-together/10k_prompts_ranked:  18%|â–ˆâ–Š        | 35/200 [01:03<05:39,  2.06s/it]Dataset: data-is-better-together/10k_prompts_ranked:  18%|â–ˆâ–Š        | 36/200 [01:05<05:23,  1.98s/it]Dataset: data-is-better-together/10k_prompts_ranked:  18%|â–ˆâ–Š        | 37/200 [01:06<05:11,  1.91s/it]Dataset: data-is-better-together/10k_prompts_ranked:  19%|â–ˆâ–‰        | 38/200 [01:08<04:50,  1.80s/it]Dataset: data-is-better-together/10k_prompts_ranked:  20%|â–ˆâ–‰        | 39/200 [01:09<04:27,  1.66s/it]Dataset: data-is-better-together/10k_prompts_ranked:  20%|â–ˆâ–ˆ        | 40/200 [01:10<04:02,  1.52s/it]Dataset: data-is-better-together/10k_prompts_ranked:  20%|â–ˆâ–ˆ        | 41/200 [01:11<03:31,  1.33s/it]Dataset: data-is-better-together/10k_prompts_ranked:  21%|â–ˆâ–ˆ        | 42/200 [01:13<04:10,  1.58s/it]Dataset: data-is-better-together/10k_prompts_ranked:  22%|â–ˆâ–ˆâ–       | 43/200 [01:15<04:12,  1.61s/it]Dataset: data-is-better-together/10k_prompts_ranked:  22%|â–ˆâ–ˆâ–       | 44/200 [01:17<04:36,  1.78s/it]Dataset: data-is-better-together/10k_prompts_ranked:  22%|â–ˆâ–ˆâ–Ž       | 45/200 [01:19<04:30,  1.75s/it]Dataset: data-is-better-together/10k_prompts_ranked:  23%|â–ˆâ–ˆâ–Ž       | 46/200 [01:20<04:07,  1.60s/it]Dataset: data-is-better-together/10k_prompts_ranked:  24%|â–ˆâ–ˆâ–Ž       | 47/200 [01:21<03:15,  1.27s/it]Dataset: data-is-better-together/10k_prompts_ranked:  24%|â–ˆâ–ˆâ–       | 48/200 [01:22<03:17,  1.30s/it]Dataset: data-is-better-together/10k_prompts_ranked:  24%|â–ˆâ–ˆâ–       | 49/200 [01:23<02:54,  1.16s/it]Dataset: data-is-better-together/10k_prompts_ranked:  25%|â–ˆâ–ˆâ–Œ       | 50/200 [01:25<03:38,  1.46s/it]Dataset: data-is-better-together/10k_prompts_ranked:  26%|â–ˆâ–ˆâ–Œ       | 51/200 [01:27<04:14,  1.71s/it]Dataset: data-is-better-together/10k_prompts_ranked:  26%|â–ˆâ–ˆâ–Œ       | 52/200 [01:29<04:04,  1.65s/it]Dataset: data-is-better-together/10k_prompts_ranked:  26%|â–ˆâ–ˆâ–‹       | 53/200 [01:30<03:23,  1.38s/it]Dataset: data-is-better-together/10k_prompts_ranked:  27%|â–ˆâ–ˆâ–‹       | 54/200 [01:30<02:54,  1.19s/it]Dataset: data-is-better-together/10k_prompts_ranked:  28%|â–ˆâ–ˆâ–Š       | 55/200 [01:31<02:08,  1.13it/s]Dataset: data-is-better-together/10k_prompts_ranked:  28%|â–ˆâ–ˆâ–Š       | 56/200 [01:32<02:16,  1.06it/s]Dataset: data-is-better-together/10k_prompts_ranked:  28%|â–ˆâ–ˆâ–Š       | 57/200 [01:34<03:12,  1.35s/it]Dataset: data-is-better-together/10k_prompts_ranked:  29%|â–ˆâ–ˆâ–‰       | 58/200 [01:34<02:18,  1.03it/s]Dataset: data-is-better-together/10k_prompts_ranked:  30%|â–ˆâ–ˆâ–‰       | 59/200 [01:36<03:02,  1.30s/it]Dataset: data-is-better-together/10k_prompts_ranked:  30%|â–ˆâ–ˆâ–ˆ       | 60/200 [01:39<03:52,  1.66s/it]Dataset: data-is-better-together/10k_prompts_ranked:  30%|â–ˆâ–ˆâ–ˆ       | 61/200 [01:39<03:16,  1.41s/it]Dataset: data-is-better-together/10k_prompts_ranked:  31%|â–ˆâ–ˆâ–ˆ       | 62/200 [01:42<04:13,  1.84s/it]Dataset: data-is-better-together/10k_prompts_ranked:  32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [01:45<04:34,  2.00s/it]Dataset: data-is-better-together/10k_prompts_ranked:  32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [01:46<03:59,  1.76s/it]Dataset: data-is-better-together/10k_prompts_ranked:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [01:48<04:04,  1.81s/it]Dataset: data-is-better-together/10k_prompts_ranked:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [01:50<04:20,  1.94s/it]Dataset: data-is-better-together/10k_prompts_ranked:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [01:52<04:14,  1.92s/it]Dataset: data-is-better-together/10k_prompts_ranked:  34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [01:53<03:59,  1.82s/it]Dataset: data-is-better-together/10k_prompts_ranked:  34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [01:54<02:56,  1.34s/it]Dataset: data-is-better-together/10k_prompts_ranked:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [01:54<02:17,  1.06s/it]Dataset: data-is-better-together/10k_prompts_ranked:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [01:54<01:44,  1.23it/s]Dataset: data-is-better-together/10k_prompts_ranked:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [01:56<02:27,  1.15s/it]Dataset: data-is-better-together/10k_prompts_ranked:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [01:58<02:48,  1.33s/it]Dataset: data-is-better-together/10k_prompts_ranked:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [01:59<02:46,  1.32s/it]Dataset: data-is-better-together/10k_prompts_ranked:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [02:02<03:20,  1.60s/it]Dataset: data-is-better-together/10k_prompts_ranked:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [02:03<03:25,  1.65s/it]Dataset: data-is-better-together/10k_prompts_ranked:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [02:05<03:33,  1.73s/it]Dataset: data-is-better-together/10k_prompts_ranked:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [02:06<03:00,  1.48s/it]Dataset: data-is-better-together/10k_prompts_ranked:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [02:09<03:34,  1.77s/it]Dataset: data-is-better-together/10k_prompts_ranked:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [02:11<03:40,  1.84s/it]Dataset: data-is-better-together/10k_prompts_ranked:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [02:13<03:43,  1.88s/it]Dataset: data-is-better-together/10k_prompts_ranked:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [02:14<03:11,  1.62s/it]Dataset: data-is-better-together/10k_prompts_ranked:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [02:15<02:52,  1.47s/it]Dataset: data-is-better-together/10k_prompts_ranked:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [02:17<03:14,  1.67s/it]Dataset: data-is-better-together/10k_prompts_ranked:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [02:19<03:27,  1.81s/it]Dataset: data-is-better-together/10k_prompts_ranked:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [02:20<03:17,  1.73s/it]Dataset: data-is-better-together/10k_prompts_ranked:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [02:22<03:21,  1.79s/it]Dataset: data-is-better-together/10k_prompts_ranked:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [02:24<03:03,  1.63s/it]Dataset: data-is-better-together/10k_prompts_ranked:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [02:26<03:11,  1.73s/it]Dataset: data-is-better-together/10k_prompts_ranked:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [02:28<03:21,  1.83s/it]Dataset: data-is-better-together/10k_prompts_ranked:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [02:28<02:43,  1.50s/it]Dataset: data-is-better-together/10k_prompts_ranked:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [02:30<02:59,  1.66s/it]Dataset: data-is-better-together/10k_prompts_ranked:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [02:32<03:04,  1.72s/it]Dataset: data-is-better-together/10k_prompts_ranked:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [02:33<02:34,  1.45s/it]Dataset: data-is-better-together/10k_prompts_ranked:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [02:35<02:46,  1.58s/it]Dataset: data-is-better-together/10k_prompts_ranked:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [02:38<03:17,  1.90s/it]Dataset: data-is-better-together/10k_prompts_ranked:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [02:39<02:44,  1.60s/it]Dataset: data-is-better-together/10k_prompts_ranked:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [02:41<02:56,  1.73s/it]Dataset: data-is-better-together/10k_prompts_ranked:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [02:43<03:02,  1.80s/it]Dataset: data-is-better-together/10k_prompts_ranked:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [02:43<02:13,  1.33s/it]Dataset: data-is-better-together/10k_prompts_ranked:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [02:44<02:19,  1.41s/it]Dataset: data-is-better-together/10k_prompts_ranked:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [02:46<02:30,  1.53s/it]Dataset: data-is-better-together/10k_prompts_ranked:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [02:48<02:43,  1.68s/it]Dataset: data-is-better-together/10k_prompts_ranked:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [02:50<02:40,  1.67s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (3654 > 2048). Running this sequence through the model will result in indexing errors
Dataset: data-is-better-together/10k_prompts_ranked:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [02:51<02:13,  1.40s/it]Dataset: data-is-better-together/10k_prompts_ranked:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [02:52<02:18,  1.47s/it]Dataset: data-is-better-together/10k_prompts_ranked:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [02:54<02:23,  1.54s/it]Dataset: data-is-better-together/10k_prompts_ranked:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [02:56<02:42,  1.77s/it]Dataset: data-is-better-together/10k_prompts_ranked:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [02:57<02:13,  1.46s/it]Dataset: data-is-better-together/10k_prompts_ranked:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [02:59<02:29,  1.66s/it]Dataset: data-is-better-together/10k_prompts_ranked:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [03:01<02:35,  1.75s/it]Dataset: data-is-better-together/10k_prompts_ranked:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [03:02<02:17,  1.56s/it]Dataset: data-is-better-together/10k_prompts_ranked:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [03:05<02:46,  1.91s/it]Dataset: data-is-better-together/10k_prompts_ranked:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [03:05<02:05,  1.46s/it]Dataset: data-is-better-together/10k_prompts_ranked:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [03:06<01:36,  1.14s/it]Dataset: data-is-better-together/10k_prompts_ranked:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [03:06<01:18,  1.07it/s]Dataset: data-is-better-together/10k_prompts_ranked:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [03:07<01:06,  1.25it/s]Dataset: data-is-better-together/10k_prompts_ranked:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [03:08<01:22,  1.01s/it]Dataset: data-is-better-together/10k_prompts_ranked:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [03:10<01:42,  1.26s/it]Dataset: data-is-better-together/10k_prompts_ranked:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [03:12<01:56,  1.46s/it]Dataset: data-is-better-together/10k_prompts_ranked:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [03:14<02:07,  1.61s/it]Dataset: data-is-better-together/10k_prompts_ranked:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [03:16<02:09,  1.66s/it]Dataset: data-is-better-together/10k_prompts_ranked:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [03:18<02:16,  1.77s/it]Dataset: data-is-better-together/10k_prompts_ranked:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [03:19<01:59,  1.57s/it]Dataset: data-is-better-together/10k_prompts_ranked:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [03:20<01:37,  1.30s/it]Dataset: data-is-better-together/10k_prompts_ranked:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [03:20<01:24,  1.14s/it]Dataset: data-is-better-together/10k_prompts_ranked:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [03:22<01:40,  1.38s/it]Dataset: data-is-better-together/10k_prompts_ranked:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [03:22<01:11,  1.01it/s]Dataset: data-is-better-together/10k_prompts_ranked:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [03:24<01:29,  1.25s/it]Dataset: data-is-better-together/10k_prompts_ranked:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [03:26<01:35,  1.37s/it]Dataset: data-is-better-together/10k_prompts_ranked:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [03:28<01:46,  1.55s/it]Dataset: data-is-better-together/10k_prompts_ranked:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [03:29<01:40,  1.47s/it]Dataset: data-is-better-together/10k_prompts_ranked:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [03:30<01:35,  1.42s/it]Dataset: data-is-better-together/10k_prompts_ranked:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [03:33<01:48,  1.65s/it]Dataset: data-is-better-together/10k_prompts_ranked:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [03:33<01:20,  1.24s/it]Dataset: data-is-better-together/10k_prompts_ranked:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [03:33<00:59,  1.07it/s]Dataset: data-is-better-together/10k_prompts_ranked:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [03:35<01:08,  1.09s/it]Dataset: data-is-better-together/10k_prompts_ranked:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [03:37<01:24,  1.36s/it]Dataset: data-is-better-together/10k_prompts_ranked:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [03:39<01:40,  1.64s/it]Dataset: data-is-better-together/10k_prompts_ranked:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [03:41<01:43,  1.73s/it]Dataset: data-is-better-together/10k_prompts_ranked:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [03:42<01:41,  1.71s/it]Dataset: data-is-better-together/10k_prompts_ranked:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [03:44<01:28,  1.53s/it]Dataset: data-is-better-together/10k_prompts_ranked:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [03:45<01:20,  1.42s/it]Dataset: data-is-better-together/10k_prompts_ranked:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [03:45<00:59,  1.05s/it]Dataset: data-is-better-together/10k_prompts_ranked:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [03:46<01:05,  1.19s/it]Dataset: data-is-better-together/10k_prompts_ranked:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [03:47<00:47,  1.13it/s]Dataset: data-is-better-together/10k_prompts_ranked:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [03:48<01:02,  1.17s/it]Dataset: data-is-better-together/10k_prompts_ranked:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [03:50<01:05,  1.25s/it]Dataset: data-is-better-together/10k_prompts_ranked:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [03:52<01:11,  1.41s/it]Dataset: data-is-better-together/10k_prompts_ranked:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [03:52<00:56,  1.13s/it]Dataset: data-is-better-together/10k_prompts_ranked:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [03:53<00:58,  1.20s/it]Dataset: data-is-better-together/10k_prompts_ranked:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [03:55<01:07,  1.40s/it]Dataset: data-is-better-together/10k_prompts_ranked:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [03:57<01:05,  1.39s/it]Dataset: data-is-better-together/10k_prompts_ranked:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [03:59<01:09,  1.52s/it]Dataset: data-is-better-together/10k_prompts_ranked:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [03:59<00:49,  1.11s/it]Dataset: data-is-better-together/10k_prompts_ranked:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [04:01<01:04,  1.46s/it]Dataset: data-is-better-together/10k_prompts_ranked:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [04:02<01:02,  1.46s/it]Dataset: data-is-better-together/10k_prompts_ranked:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [04:04<01:04,  1.54s/it]Dataset: data-is-better-together/10k_prompts_ranked:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [04:05<00:58,  1.44s/it]Dataset: data-is-better-together/10k_prompts_ranked:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [04:07<00:59,  1.49s/it]Dataset: data-is-better-together/10k_prompts_ranked:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [04:08<00:58,  1.49s/it]Dataset: data-is-better-together/10k_prompts_ranked:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [04:10<00:59,  1.57s/it]Dataset: data-is-better-together/10k_prompts_ranked:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [04:11<00:46,  1.27s/it]Dataset: data-is-better-together/10k_prompts_ranked:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [04:12<00:46,  1.28s/it]Dataset: data-is-better-together/10k_prompts_ranked:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [04:14<00:50,  1.46s/it]Dataset: data-is-better-together/10k_prompts_ranked:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [04:16<00:55,  1.63s/it]Dataset: data-is-better-together/10k_prompts_ranked:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [04:18<01:00,  1.84s/it]Dataset: data-is-better-together/10k_prompts_ranked:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [04:20<00:59,  1.87s/it]Dataset: data-is-better-together/10k_prompts_ranked:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [04:23<01:01,  1.99s/it]Dataset: data-is-better-together/10k_prompts_ranked:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [04:24<00:55,  1.85s/it]Dataset: data-is-better-together/10k_prompts_ranked:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [04:26<00:57,  1.98s/it]Dataset: data-is-better-together/10k_prompts_ranked:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [04:28<00:55,  1.98s/it]Dataset: data-is-better-together/10k_prompts_ranked:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [04:30<00:51,  1.91s/it]Dataset: data-is-better-together/10k_prompts_ranked:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [04:32<00:49,  1.90s/it]Dataset: data-is-better-together/10k_prompts_ranked:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [04:34<00:49,  1.97s/it]Dataset: data-is-better-together/10k_prompts_ranked:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [04:36<00:48,  2.03s/it]Dataset: data-is-better-together/10k_prompts_ranked:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [04:39<00:50,  2.18s/it]Dataset: data-is-better-together/10k_prompts_ranked:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [04:40<00:45,  2.05s/it]Dataset: data-is-better-together/10k_prompts_ranked:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [04:43<00:44,  2.10s/it]Dataset: data-is-better-together/10k_prompts_ranked:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [04:44<00:34,  1.73s/it]Dataset: data-is-better-together/10k_prompts_ranked:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [04:44<00:25,  1.36s/it]Dataset: data-is-better-together/10k_prompts_ranked:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [04:46<00:25,  1.40s/it]Dataset: data-is-better-together/10k_prompts_ranked:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [04:46<00:19,  1.16s/it]Dataset: data-is-better-together/10k_prompts_ranked:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [04:47<00:18,  1.13s/it]Dataset: data-is-better-together/10k_prompts_ranked:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [04:49<00:20,  1.37s/it]Dataset: data-is-better-together/10k_prompts_ranked:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [04:51<00:21,  1.52s/it]Average accept_length over 54 steps: 3.8148
Average accept_length over 55 steps: 3.7455
Average accept_length over 67 steps: 1.5075
Average accept_length over 73 steps: 2.5479
Average accept_length over 9 steps: 2.7778
Average accept_length over 61 steps: 3.3279
Average accept_length over 57 steps: 3.5965
Average accept_length over 31 steps: 3.1613
Average accept_length over 48 steps: 4.4167
Average accept_length over 39 steps: 5.4103
Average accept_length over 61 steps: 3.2131
Average accept_length over 14 steps: 2.1429
Average accept_length over 52 steps: 2.2308
Average accept_length over 46 steps: 4.6739
Average accept_length over 38 steps: 5.9211
Average accept_length over 76 steps: 2.3947
Average accept_length over 55 steps: 3.7455
Average accept_length over 32 steps: 4.3750
Average accept_length over 38 steps: 2.9474
Average accept_length over 23 steps: 2.4348
Average accept_length over 52 steps: 2.6346
Average accept_length over 46 steps: 4.6739
Average accept_length over 52 steps: 3.5000
Average accept_length over 76 steps: 2.4211
Average accept_length over 57 steps: 3.3860
Average accept_length over 50 steps: 4.1600
Average accept_length over 48 steps: 3.8958
Average accept_length over 41 steps: 3.5122
Average accept_length over 66 steps: 2.9091
Average accept_length over 62 steps: 3.1613
Average accept_length over 58 steps: 3.5172
Average accept_length over 78 steps: 2.2949
Average accept_length over 52 steps: 3.9615
Average accept_length over 44 steps: 3.7273
Average accept_length over 68 steps: 2.8382
Average accept_length over 51 steps: 4.0588
Average accept_length over 51 steps: 4.0392
Average accept_length over 42 steps: 5.2143
Average accept_length over 39 steps: 1.1026
Average accept_length over 33 steps: 4.1212
Average accept_length over 25 steps: 3.3200
Average accept_length over 62 steps: 3.2097
Average accept_length over 48 steps: 3.2708
Average accept_length over 63 steps: 3.1270
Average accept_length over 48 steps: 4.4167
Average accept_length over 36 steps: 5.3333
Average accept_length over 14 steps: 2.8571
Average accept_length over 39 steps: 2.6667
Average accept_length over 23 steps: 3.1304
Average accept_length over 62 steps: 3.2258
Average accept_length over 66 steps: 2.9394
Average accept_length over 43 steps: 5.0930
Average accept_length over 21 steps: 3.0476
Average accept_length over 21 steps: 3.4286
Average accept_length over 4 steps: 2.7500
Average accept_length over 31 steps: 4.4194
Average accept_length over 66 steps: 2.9242
Average accept_length over 2 steps: 1.0000
Average accept_length over 59 steps: 3.4068
Average accept_length over 73 steps: 2.5479
Average accept_length over 23 steps: 4.9130
Average accept_length over 82 steps: 2.1951
Average accept_length over 69 steps: 2.7971
Average accept_length over 34 steps: 4.0294
Average accept_length over 54 steps: 3.7778
Average accept_length over 56 steps: 3.2143
Average accept_length over 51 steps: 4.0392
Average accept_length over 45 steps: 4.8667
Average accept_length over 6 steps: 3.8333
Average accept_length over 10 steps: 3.9000
Average accept_length over 6 steps: 3.1667
Average accept_length over 55 steps: 3.6182
Average accept_length over 49 steps: 3.5714
Average accept_length over 37 steps: 4.2162
Average accept_length over 64 steps: 3.0312
Average accept_length over 50 steps: 4.2400
Average accept_length over 54 steps: 3.7778
Average accept_length over 25 steps: 2.9200
Average accept_length over 69 steps: 2.7391
Average accept_length over 56 steps: 3.6607
Average accept_length over 56 steps: 3.6786
Average accept_length over 29 steps: 2.4828
Average accept_length over 32 steps: 3.1562
Average accept_length over 62 steps: 3.1613
Average accept_length over 61 steps: 3.2131
Average accept_length over 42 steps: 5.1190
Average accept_length over 54 steps: 3.7778
Average accept_length over 35 steps: 4.0857
Average accept_length over 54 steps: 3.8148
Average accept_length over 59 steps: 3.4237
Average accept_length over 20 steps: 4.2000
Average accept_length over 57 steps: 3.5439
Average accept_length over 53 steps: 3.9245
Average accept_length over 23 steps: 3.5217
Average accept_length over 52 steps: 3.9808
Average accept_length over 75 steps: 2.4267
Average accept_length over 25 steps: 3.3600
Average accept_length over 58 steps: 3.4655
Average accept_length over 55 steps: 3.6727
Average accept_length over 6 steps: 2.8333
Average accept_length over 44 steps: 4.8636
Average accept_length over 52 steps: 3.4615
Average accept_length over 58 steps: 3.2241
Average accept_length over 45 steps: 4.7111
Average accept_length over 1 steps: 0.0000
Average accept_length over 45 steps: 4.7111
Average accept_length over 45 steps: 4.7111
Average accept_length over 65 steps: 2.9538
Average accept_length over 21 steps: 2.7143
Average accept_length over 60 steps: 3.3000
Average accept_length over 55 steps: 3.6909
Average accept_length over 31 steps: 4.4839
Average accept_length over 77 steps: 2.3377
Average accept_length over 10 steps: 6.1000
Average accept_length over 11 steps: 2.2727
Average accept_length over 12 steps: 2.9167
Average accept_length over 13 steps: 3.1538
Average accept_length over 41 steps: 5.4390
Average accept_length over 52 steps: 3.9615
Average accept_length over 53 steps: 3.8868
Average accept_length over 55 steps: 3.6909
Average accept_length over 51 steps: 4.0392
Average accept_length over 57 steps: 3.5088
Average accept_length over 31 steps: 2.8387
Average accept_length over 19 steps: 3.1579
Average accept_length over 21 steps: 4.5238
Average accept_length over 55 steps: 3.7091
Average accept_length over 2 steps: 6.0000
Average accept_length over 54 steps: 3.7963
Average accept_length over 48 steps: 2.2500
Average accept_length over 57 steps: 3.5263
Average accept_length over 37 steps: 4.3784
Average accept_length over 38 steps: 3.1053
Average accept_length over 64 steps: 3.0312
Average accept_length over 8 steps: 3.2500
Average accept_length over 5 steps: 4.8000
Average accept_length over 43 steps: 3.4651
Average accept_length over 57 steps: 3.5088
Average accept_length over 67 steps: 2.8358
Average accept_length over 56 steps: 2.7857
Average accept_length over 47 steps: 4.5106
Average accept_length over 31 steps: 3.9677
Average accept_length over 33 steps: 3.1515
Average accept_length over 5 steps: 3.2000
Average accept_length over 42 steps: 5.1429
Average accept_length over 4 steps: 5.2500
Average accept_length over 52 steps: 3.9808
Average accept_length over 41 steps: 4.7561
Average accept_length over 51 steps: 4.0588
Average accept_length over 12 steps: 2.2500
Average accept_length over 38 steps: 4.1053
Average accept_length over 54 steps: 3.8519
Average accept_length over 39 steps: 3.1282
Average accept_length over 52 steps: 4.0769
Average accept_length over 3 steps: 3.6667
Average accept_length over 66 steps: 2.9242
Average accept_length over 40 steps: 5.5750
Average accept_length over 50 steps: 4.1400
Average accept_length over 34 steps: 5.6471
Average accept_length over 46 steps: 4.5870
Average accept_length over 43 steps: 3.0233
Average accept_length over 49 steps: 4.2653
Average accept_length over 10 steps: 4.4000
Average accept_length over 38 steps: 3.5000
Average accept_length over 54 steps: 3.8519
Average accept_length over 59 steps: 3.3898
Average accept_length over 69 steps: 2.7246
Average accept_length over 56 steps: 3.5893
Average accept_length over 66 steps: 2.9091
Average accept_length over 31 steps: 3.5484
Average accept_length over 65 steps: 2.9538
Average accept_length over 58 steps: 3.4483
Average accept_length over 50 steps: 4.2000
Average accept_length over 55 steps: 3.0182
Average accept_length over 62 steps: 3.2097
Average accept_length over 63 steps: 3.0952
Average accept_length over 74 steps: 2.4730
Average accept_length over 50 steps: 4.1800
Average accept_length over 64 steps: 3.0625
Average accept_length over 25 steps: 4.1200
Average accept_length over 13 steps: 4.6923
Average accept_length over 43 steps: 5.0465
Average accept_length over 17 steps: 2.4706
Average accept_length over 31 steps: 2.0323
Average accept_length over 56 steps: 3.5893
Average accept_length over 54 steps: 3.8704
Dataset: data-is-better-together/10k_prompts_ranked:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [04:53<00:20,  1.61s/it]Dataset: data-is-better-together/10k_prompts_ranked:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [04:54<00:16,  1.38s/it]Dataset: data-is-better-together/10k_prompts_ranked:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [04:55<00:14,  1.28s/it]Dataset: data-is-better-together/10k_prompts_ranked:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [04:56<00:13,  1.38s/it]Dataset: data-is-better-together/10k_prompts_ranked:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [04:58<00:14,  1.56s/it]Dataset: data-is-better-together/10k_prompts_ranked:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [04:58<00:09,  1.13s/it]Dataset: data-is-better-together/10k_prompts_ranked:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [05:00<00:07,  1.13s/it]Dataset: data-is-better-together/10k_prompts_ranked:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [05:02<00:08,  1.39s/it]Dataset: data-is-better-together/10k_prompts_ranked:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [05:03<00:07,  1.49s/it]Dataset: data-is-better-together/10k_prompts_ranked:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [05:04<00:04,  1.16s/it]Dataset: data-is-better-together/10k_prompts_ranked:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [05:05<00:04,  1.34s/it]Dataset: data-is-better-together/10k_prompts_ranked:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [05:07<00:03,  1.53s/it]Dataset: data-is-better-together/10k_prompts_ranked: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [05:09<00:01,  1.57s/it]Dataset: data-is-better-together/10k_prompts_ranked: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [05:11<00:00,  1.57s/it]Dataset: data-is-better-together/10k_prompts_ranked: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [05:11<00:00,  1.56s/it]
Average accept_length over 53 steps: 3.8679
Average accept_length over 24 steps: 1.8333
Average accept_length over 30 steps: 4.0667
Average accept_length over 46 steps: 4.6522
Average accept_length over 58 steps: 3.5000
Average accept_length over 2 steps: 2.5000
Average accept_length over 30 steps: 3.7333
Average accept_length over 59 steps: 3.3729
Average accept_length over 50 steps: 4.1800
Average accept_length over 11 steps: 3.5455
Average accept_length over 50 steps: 4.1400
Average accept_length over 58 steps: 2.9310
Average accept_length over 47 steps: 4.4681
Average accept_length over 45 steps: 4.7333
ðŸ”„ Completions saved to /home/ubuntu/sd/HandEval/outputs/eagleT0.7_vicuna-13b-v1.3/data-is-better-together/10k_prompts_ranked_completions.jsonl

âœ…  Results saved to /home/ubuntu/sd/HandEval/outputs/eagleT0.7_vicuna-13b-v1.3/data-is-better-together/10k_prompts_ranked_metrics.json
{
  "num_samples": 200,
  "total_time_sec": 311.15923619270325,
  "avg_time_per_sample_sec": 1.5557961809635161,
  "samples_file": "outputs/eagleT0.7_vicuna-13b-v1.3/data-is-better-together/10k_prompts_ranked_completions.jsonl"
}
